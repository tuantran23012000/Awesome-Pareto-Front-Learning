# Awesome Pareto Front Learning / Pareto Multi Task Learning
A collection of Awesome papers on Pareto Front Learning, Pareto Multi Task Learning, Multiple Gradient Descent methods to solve Multi-Objective Optimization, Multi-Task Learning as Multi-Objective Optimization, and Optimization in Pareto Set.

## Paper
### Multiple Gradient Descent
#### 2023
 - Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Approach [[ICLR 2023](https://openreview.net/forum?id=dLAYGdKTi2)] [[code](https://github.com/median-research-group/LibMTL)]
 - Independent Component Alignment for Multi-Task Learning  [[CVPR 2023](https://openaccess.thecvf.com/content/CVPR2023/html/Senushkin_Independent_Component_Alignment_for_Multi-Task_Learning_CVPR_2023_paper.html)] [[code](https://github.com/SamsungLabs/MTL)]
#### 2022
 - Stochastic Multiple Target Sampling Gradient Descent [[NeurIPS 2022](https://arxiv.org/abs/2206.01934?fbclid=IwAR0DctSaeZhpvgJeYZO1RNCxCy4DR-PSB65qKOFklALv2rCyUw6W2sNAssw)] [[code](https://github.com/VietHoang1512/MT-SGD)]
 - Multi-Task Learning as a Bargaining Game  [[ICML 2022](https://arxiv.org/pdf/2202.01017.pdf)] [[code](https://github.com/AvivNavon/nash-mtl.git)]
 - Reasonable Effectiveness of Random Weighting: A Litmus Test for Multi-Task Learning [[TMLR 2022](https://openreview.net/forum?id=jjtFD8A1Wx)] [[code](https://github.com/median-research-group/LibMTL)]
 - A Multi-objective / Multi-task Learning Framework Induced by Pareto Stationarity [[ICML 2022](https://proceedings.mlr.press/v162/momma22a.html)]
#### 2021
 - Profiling Pareto Front With Multi-Objective Stein Variational Gradient Descent [[NeurIPS 2021 (Spotlight)](https://proceedings.neurips.cc/paper/2021/file/7bb16972da003e87724f048d76b7e0e1-Paper.pdf)] [[code](https://github.com/gnobitab/MultiObjectiveSampling)]
 - Conflict-Averse Gradient Descent for Multi-task Learning [[NeurIPS 2021](https://arxiv.org/pdf/2110.14048.pdf)] [[code](https://github.com/Cranial-XIX/CAGrad.git)]
 - Towards Impartial Multi-task Learning [[ICLR 2021](https://openreview.net/pdf?id=IMPnRXEWpvr)] [[code](https://github.com/AvivNavon/nash-mtl.git)]
 - Controllable Pareto Multi-Task Learning [[Arxiv 2021](https://arxiv.org/pdf/2010.06313.pdf)] [[code](https://openreview.net/attachment?id=5mhViEOQxaV&name=supplementary_material)]
 - Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models [[ICLR 2021](https://openreview.net/forum?id=F1vEjWK-lH_)] [[code](https://github.com/median-research-group/LibMTL)]
#### 2020
 - Multi-Task Learning with User Preferences Gradient Descent with Controlled Ascent in Pareto Optimization [[ICML 2020](http://proceedings.mlr.press/v119/mahapatra20a/mahapatra20a.pdf)] [[code](https://github.com/dbmptr/EPOSearch)]
 - Gradient Surgery for Multi-Task Learning [[NeurIPS 2020](https://arxiv.org/pdf/2001.06782.pdf)] [[code](https://github.com/WeiChengTseng/Pytorch-PCGrad.git)]
#### 2019
 - Pareto Multi-Task Learning  [[NeurIPS 2019](https://proceedings.neurips.cc/paper/2019/file/685bfde03eb646c27ed565881917c71c-Paper.pdf)] [[code](https://github.com/Xi-L/ParetoMTL)]
#### 2018
 - Multi-Task Learning as Multi-Objective Optimization [[NIPS 2018](https://arxiv.org/pdf/1810.04650.pdf)] [[code](https://github.com/isl-org/MultiObjectiveOptimization)]

### Pareto Set/Pareto Front Learning
#### 2023
 - A framework for controllable pareto front learning with completed scalarization functions and its applications [[Arxiv 2023](https://arxiv.org/pdf/2302.12487)] [[code](https://github.com/tuantran23012000/PHN-CSF)]
 - Pareto Manifold Learning: Tackling multiple tasks via ensembles of single-task models [[ICML 2023](https://proceedings.mlr.press/v202/dimitriadis23a.html)] [[code](https://github.com/nik-dim/pamal)]
 - Improving Pareto Front Learning via Multi-Sample Hypernetworks [[AAAI 2023](https://arxiv.org/pdf/2212.01130.pdf)] [[code](https://github.com/longhoangphi225/MultiSample-Hypernetworks.git)]
#### 2022
 - Pareto Set Learning for Neural Multi-Objective Combinatorial Optimization [[ICLR 2022](https://arxiv.org/pdf/2203.15386.pdf)][[code](https://github.com/Xi-L/PMOCO.git)]
 - Pareto Set Learning for Expensive Multi-Objective Optimization [[NeurIPS 2022](https://arxiv.org/pdf/2203.15386.pdf)][[code](https://github.com/Xi-L/PSL-MOBO.git)]
#### 2021
 - Multi-Objective Learning to Predict Pareto Fronts Using Hypervolume Maximization [[Arxiv 2021](https://arxiv.org/pdf/2102.04523.pdf)] [[code](https://github.com/timodeist/multi_objective_learning)]
 - Self-Evolutionary Optimization for Pareto Front Learning [[Arxiv 2021](https://arxiv.org/pdf/2110.03461.pdf)]
 - Learning the Pareto Front with Hypernetworks [[ICLR 2021](https://arxiv.org/pdf/2010.04104.pdf)][[code](https://github.com/AvivNavon/pareto-hypernetworks.git)]
 - Scalable Pareto Front Approximation for Deep Multi-Objective Learning [[ICDM 2021](https://arxiv.org/pdf/2103.13392.pdf)] [[code](https://github.com/ruchtem/cosmos)]
#### 2020
 - Effcient Continuous Pareto Exploration in Multi-Task Learning [[ICML 2020](http://proceedings.mlr.press/v119/ma20a/ma20a.pdf)] [[code](https://github.com/mit-gfx/ContinuousParetoMTL)]


### Optimization in Pareto Set
 - Pareto Navigation Gradient Descent: a First-Order Algorithm for Optimization in Pareto Set [[UAI 2022](https://arxiv.org/pdf/2110.08713)][[code](https://openreview.net/attachment?id=tiKNfYpH8le&name=supplementary_material)]
 - Pareto Efficient Fairness in Supervised Learning: From Extraction to Tracing [[Arxiv 2021](https://arxiv.org/pdf/2104.01634.pdf)]
<!-- ### Conference
 - Learning with Privileged Tasks [[ICCV 2021](https://openaccess.thecvf.com/content/ICCV2021/html/Song_Learning_With_Privileged_Tasks_ICCV_2021_paper.html)] 
 - A Multi-objective / Multi-task Learning Framework Induced by Pareto Stationarity [[ICML 2022](https://proceedings.mlr.press/v162/momma22a.html)] -->


